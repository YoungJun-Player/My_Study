{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "목적함수의 결과값을 최적화하는 변수를 찾는 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 가중치에서는 오차가 가장 작으며 최적의 가중치에서 멀어질수록 오차가 커지는 것을 확인할 수 있다\n",
    "\n",
    "얼마나 이동해야하는지 알 수 없기 때문에 최적화 방법을 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사 하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수의 기울기가 낮은 곳으로 계속 이동시켜 극값에 도달할 때 까지 반복하는 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기울기가 0을 가지게 되는 가중치를 찾을 때 까지 반복하게 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치를 갱신할 때 a를 곱해 가중치 결과를 조정한다\n",
    "\n",
    "이 때 a를 학습률이라고 한다 \n",
    "\n",
    "초기값을 임의로 설정한다\n",
    "\n",
    "적절하지 않은 학습률은 너무 많은 반복이 필요하거나 아무리 반복해도 최적의 해를 찾기 어려울 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적화 알고리즘은 경사하강법 이외에도 모멘텀, Adagrad,Adam 등이 있다 보통 Adam을 쓴다 최적화 한 값을 찾아주기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단순 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[0.8538]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0748], requires_grad=True)], Cost : 1.434\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[0.8633]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1181], requires_grad=True)], Cost : 1.396\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[0.8692]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2382], requires_grad=True)], Cost : 1.382\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[0.8728]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3129], requires_grad=True)], Cost : 1.376\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[0.8751]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3593], requires_grad=True)], Cost : 1.374\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[0.8766]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3883], requires_grad=True)], Cost : 1.373\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[0.8774]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4063], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[0.8780]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4175], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[0.8783]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4244], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[0.8785]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4288], requires_grad=True)], Cost : 1.372\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "# 데이터 선언\n",
    "x = torch.FloatTensor([\n",
    "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
    "])\n",
    "y = torch.FloatTensor([\n",
    "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
    "])\n",
    "\n",
    "# 모델 선언\n",
    "model = nn.Linear(1, 1)\n",
    "\n",
    "# 손실함수 선언\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 최적화 선언\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    output = model(x)\n",
    "    cost = criterion(output, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
